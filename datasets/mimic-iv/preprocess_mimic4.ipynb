{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets.preprocess.tools import forward_fill_pipeline, normalize_dataframe, normalize_df_with_statistics\n",
    "\n",
    "data_dir = \"./datasets/mimic-iv/\"\n",
    "Path(os.path.join(data_dir, 'processed')).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(data_dir, 'statistics')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_records = ['PatientID', 'RecordTime', 'AdmissionTime', 'DischargeTime']\n",
    "target_features = ['Outcome', 'LOS']\n",
    "demographic_features = ['Sex', 'Age'] # Sex and ICUType are binary features, others are continuous features\n",
    "labtest_features = ['Capillary refill rate->0.0', 'Capillary refill rate->1.0',\n",
    "        'Glascow coma scale eye opening->To Pain',\n",
    "        'Glascow coma scale eye opening->3 To speech',\n",
    "        'Glascow coma scale eye opening->1 No Response',\n",
    "        'Glascow coma scale eye opening->4 Spontaneously',\n",
    "        'Glascow coma scale eye opening->None',\n",
    "        'Glascow coma scale eye opening->To Speech',\n",
    "        'Glascow coma scale eye opening->Spontaneously',\n",
    "        'Glascow coma scale eye opening->2 To pain',\n",
    "        'Glascow coma scale motor response->1 No Response',\n",
    "        'Glascow coma scale motor response->3 Abnorm flexion',\n",
    "        'Glascow coma scale motor response->Abnormal extension',\n",
    "        'Glascow coma scale motor response->No response',\n",
    "        'Glascow coma scale motor response->4 Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Localizes Pain',\n",
    "        'Glascow coma scale motor response->Flex-withdraws',\n",
    "        'Glascow coma scale motor response->Obeys Commands',\n",
    "        'Glascow coma scale motor response->Abnormal Flexion',\n",
    "        'Glascow coma scale motor response->6 Obeys Commands',\n",
    "        'Glascow coma scale motor response->5 Localizes Pain',\n",
    "        'Glascow coma scale motor response->2 Abnorm extensn',\n",
    "        'Glascow coma scale total->11', 'Glascow coma scale total->10',\n",
    "        'Glascow coma scale total->13', 'Glascow coma scale total->12',\n",
    "        'Glascow coma scale total->15', 'Glascow coma scale total->14',\n",
    "        'Glascow coma scale total->3', 'Glascow coma scale total->5',\n",
    "        'Glascow coma scale total->4', 'Glascow coma scale total->7',\n",
    "        'Glascow coma scale total->6', 'Glascow coma scale total->9',\n",
    "        'Glascow coma scale total->8',\n",
    "        'Glascow coma scale verbal response->1 No Response',\n",
    "        'Glascow coma scale verbal response->No Response',\n",
    "        'Glascow coma scale verbal response->Confused',\n",
    "        'Glascow coma scale verbal response->Inappropriate Words',\n",
    "        'Glascow coma scale verbal response->Oriented',\n",
    "        'Glascow coma scale verbal response->No Response-ETT',\n",
    "        'Glascow coma scale verbal response->5 Oriented',\n",
    "        'Glascow coma scale verbal response->Incomprehensible sounds',\n",
    "        'Glascow coma scale verbal response->1.0 ET/Trach',\n",
    "        'Glascow coma scale verbal response->4 Confused',\n",
    "        'Glascow coma scale verbal response->2 Incomp sounds',\n",
    "        'Glascow coma scale verbal response->3 Inapprop words',\n",
    "        'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
    "        'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
    "        'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
    "        'pH']\n",
    "require_impute_features = labtest_features\n",
    "normalize_features = ['Age'] + ['Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
    "        'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
    "        'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
    "        'pH'] + ['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"processed\", f\"format_mimic4_ehr.csv\"))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a patient has multiple records, we only use the first 48 items\n",
    "# we also discard the patients with less than 48 items\n",
    "\n",
    "# Ensure dataframe is sorted by PatientID and RecordTime\n",
    "df = df.sort_values(['PatientID', 'RecordTime'])\n",
    "\n",
    "# Filter out patients with less than 48 records\n",
    "df = df.groupby('PatientID').filter(lambda x: len(x) >= 48)\n",
    "\n",
    "# Select the first 48 records for each patient\n",
    "df = df.groupby('PatientID').head(48)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_group(rt):\n",
    "    return (rt - 1) // 12\n",
    "\n",
    "# Assign group for each record\n",
    "df['Group'] = df['RecordTime'].apply(assign_group)\n",
    "\n",
    "aggregation_logic = {}\n",
    "for f in demographic_features+labtest_features:\n",
    "    aggregation_logic[f] = 'mean'\n",
    "\n",
    "aggregation_logic['Outcome'] = 'mean'\n",
    "aggregation_logic['LOS'] = 'mean'\n",
    "\n",
    "\n",
    "# Group by PatientID and Group, then aggregate\n",
    "aggregated_df = df.groupby(['PatientID', 'Group']).agg(aggregation_logic)  # replace 'mean' with your desired aggregation\n",
    "\n",
    "# Reset index if needed\n",
    "aggregated_df = aggregated_df.reset_index()\n",
    "\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = aggregated_df.rename(columns={'Group':'RecordTime'})\n",
    "df = aggregated_df\n",
    "\n",
    "df['LOS'] = 5-df['RecordTime']\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split dataset into `Training`, `Validation` and `Test` sets (ML/DL settings)\n",
    "\n",
    "- Stratified dataset according to `Outcome` column\n",
    "- 50% Training, 45% Validation, 5% Test\n",
    "  - Name: train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Get the patient IDs and outcomes\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in patients])\n",
    "\n",
    "# Get the train_val/test patient IDs\n",
    "train_val_patients, test_patients = train_test_split(patients, test_size=5/100, random_state=SEED, stratify=patients_outcome)\n",
    "\n",
    "# Get the train/val patient IDs\n",
    "train_val_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_val_patients])\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=45/95, random_state=SEED, stratify=train_val_patients_outcome)\n",
    "# Create train, val, test dataframes for the current fold\n",
    "train_df = df[df['PatientID'].isin(train_patients)]\n",
    "val_df = df[df['PatientID'].isin(val_patients)]\n",
    "test_df = df[df['PatientID'].isin(test_patients)]\n",
    "save_dir = os.path.join(data_dir, 'processed', 'fold_ml') # forward fill\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Save the train, val, and test dataframes for the current fold to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_raw.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_raw.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_raw.csv\"), index=False)\n",
    "# Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "train_df, val_df, test_df, default_fill, los_info, train_mean, train_std = normalize_dataframe(train_df, val_df, test_df, normalize_features)\n",
    "\n",
    "# # Save the zscored dataframes to csv files\n",
    "# train_df.to_csv(os.path.join(save_dir, \"train_after_zscore.csv\"), index=False)\n",
    "# val_df.to_csv(os.path.join(save_dir, \"val_after_zscore.csv\"), index=False)\n",
    "# test_df.to_csv(os.path.join(save_dir, \"test_after_zscore.csv\"), index=False)\n",
    "\n",
    "# Forward Imputation after grouped by PatientID\n",
    "# Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "train_x, train_y, train_pid, _ = forward_fill_pipeline(train_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "val_x, val_y, val_pid, _ = forward_fill_pipeline(val_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "test_x, test_y, test_pid, _ = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "# Save the imputed dataset to pickle file\n",
    "pd.to_pickle(train_x, os.path.join(save_dir, \"train_x.pkl\"))\n",
    "pd.to_pickle(train_y, os.path.join(save_dir, \"train_y.pkl\"))\n",
    "pd.to_pickle(train_pid, os.path.join(save_dir, \"train_pid.pkl\"))\n",
    "pd.to_pickle(val_x, os.path.join(save_dir, \"val_x.pkl\"))\n",
    "pd.to_pickle(val_y, os.path.join(save_dir, \"val_y.pkl\"))\n",
    "pd.to_pickle(val_pid, os.path.join(save_dir, \"val_pid.pkl\"))\n",
    "pd.to_pickle(test_x, os.path.join(save_dir, \"test_x.pkl\"))\n",
    "pd.to_pickle(test_y, os.path.join(save_dir, \"test_y.pkl\"))\n",
    "pd.to_pickle(test_pid, os.path.join(save_dir, \"test_pid.pkl\"))\n",
    "pd.to_pickle(los_info, os.path.join(save_dir, \"los_info.pkl\")) # LOS statistics (calculated from the train set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out dataset setting (Stratified) LLM settings\n",
    "\n",
    "- 50% training, 45% validation, 5% testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by patient ID\n",
    "grouped = df.groupby('PatientID')\n",
    "\n",
    "# Get the patient IDs and outcomes\n",
    "patients = np.array(list(grouped.groups.keys()))\n",
    "patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in patients])\n",
    "\n",
    "# Get the train_val/test patient IDs\n",
    "train_val_patients, test_patients = train_test_split(patients, test_size=5/100, random_state=SEED, stratify=patients_outcome)\n",
    "\n",
    "# Get the train/val patient IDs\n",
    "train_val_patients_outcome = np.array([grouped.get_group(patient_id)['Outcome'].iloc[0] for patient_id in train_val_patients])\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=45/95, random_state=SEED, stratify=train_val_patients_outcome)\n",
    "# Create train, val, test dataframes for the current fold\n",
    "train_df = df[df['PatientID'].isin(train_patients)]\n",
    "val_df = df[df['PatientID'].isin(val_patients)]\n",
    "test_df = df[df['PatientID'].isin(test_patients)]\n",
    "save_dir = os.path.join(data_dir, 'processed', 'fold_llm') # forward fill\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Calculate the mean and std of the train set (include age, lab test features, and LOS) on the data in 5% to 95% quantile range\n",
    "default_fill = normalize_dataframe(train_df, val_df, test_df, normalize_features, require_norm_later=False)\n",
    "\n",
    "# Forward Imputation after grouped by PatientID\n",
    "# Notice: if a patient has never done certain lab test, the imputed value will be the median value calculated from train set\n",
    "\n",
    "test_x, test_y, test_pid, test_x_record_times = forward_fill_pipeline(test_df, default_fill, demographic_features, labtest_features, target_features, require_impute_features)\n",
    "\n",
    "# Save the imputed dataset to pickle file\n",
    "pd.to_pickle(test_x, os.path.join(save_dir, \"test_x.pkl\"))\n",
    "pd.to_pickle(test_y, os.path.join(save_dir, \"test_y.pkl\"))\n",
    "pd.to_pickle(test_pid, os.path.join(save_dir, \"test_pid.pkl\"))\n",
    "pd.to_pickle(los_info, os.path.join(save_dir, \"los_info.pkl\")) # LOS statistics (calculated from the train set)\n",
    "pd.to_pickle(test_x_record_times, os.path.join(save_dir, \"test_x_record_times.pkl\"))\n",
    "\n",
    "all_features = demographic_features + labtest_features\n",
    "pd.to_pickle(all_features, os.path.join(save_dir, \"all_features.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
